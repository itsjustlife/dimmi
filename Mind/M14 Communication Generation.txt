Module M14: Communication Generation Module

---
Module: M14_Communication_Generation
Version: 1.0
Purpose: Construct clear, context-appropriate natural language responses to deliver to the user
Triggers: [ "Response_Request", "Final_Answer_Preparation" ]
Inputs: [ "Inference_Result from M08 or Final_Data", "Conversation_Context", "User_Preferences" ]
Outputs: [ "Outgoing_Message" ]
Dependencies: [ "M11_Safety_Alignment", "M15_User_Profile" ]
Safety_Level: Moderate
Checksum: 55acd8dfa0f9d3b9f548944d897d0371
---

PURPOSE:
 The Communication Generation Module is the AI’s “voice”. After the decision engine decides that it’s time to respond to the user (with an answer, clarification question, or any message), M14 takes the content (the raw answer or result) and forms a well-structured, polite, and contextually appropriate message. It ensures the tone and format align with user preferences (like formality or language style) and with any system guidelines (like including sources if required, or keeping the response length in check). Essentially, M14 turns thoughts into speech/text, similar to how we internally think of an answer then choose how to phrase it when speaking.

INPUTS:
 - **Inference_Result or Final_Data:** The core content to communicate. This usually comes from M08 (if it’s an answer the AI reasoned out) or directly from an action result (like M10 if the action was, say, retrieving a definition). It might be textual or structured (like a list of bullet points) that needs converting to natural language.
 - **Conversation_Context:** The recent dialogue and context from M03 short-term memory (and possibly user profile from M15) to maintain coherence. This helps with:
   - Referencing things properly (e.g., using the same terminology the user used, or not repeating what was said).
   - Deciding if the answer should be brief (if user seems impatient or if it was a simple question) or detailed (if user asked broadly or explicitly said "explain in detail").
   - Possibly includes the original question to directly address it.
 - **User_Preferences:** Data from M15 indicating style preferences. For instance:
   - The user’s preferred form of address (formal vs casual, or pronouns if applicable).
   - If the user likes visual output (maybe not applicable in text only, but could be if formatting choices, or whether to use markdown, etc.).
   - Language preference if multilingual environment.
   - Any other settings like "explain reasoning" or "just give answer".
   - If none provided, default to a neutral, polite tone.
 - Additionally, any high-level system directive like "be concise" or "the user is a child, simplify language" could come via this input or profile.

OUTPUTS:
 - **Outgoing_Message:** The final message text to send to the user. This is phrased in complete sentences, logically ordered, and hopefully free of any raw notation or confusing jargon unless appropriate.
   - It may incorporate slight rewording or additional context: e.g., “The population of France is about 67 million as of 2021.” instead of just “67 million” to make it a complete answer.
   - If the system design allows, could include formatting (like bullet points if listing items, or markdown for code etc., in a chat UI context).
   - It should implicitly or explicitly answer the user's question or respond to their request at this stage.
   - This output will pass through M11 for final safety filtering before reaching the user, but M14 should already strive to avoid content that M11 would cut (like it shouldn't purposely include known disallowed phrases).
 - M14 might also handle some conversational niceties:
   - E.g., if this is the first answer, maybe it starts with "Sure, here's what I found:" vs if it's a follow-up, it might refer back to prior context (“As mentioned earlier, ...”).
   - If user asked multiple questions in one go, it might format answer sections.
   - It could manage the closing of conversation (like offering further help if appropriate).
 - Importantly, M14 does not decide *what* to say (that’s M08/M09’s job); it decides *how to say it*.

DETAILED_DECISION_LOGIC:
 1. **Determine Tone and Style**:
    - Check User_Preferences (from M15):
      - Formal vs informal: e.g., if preference says “casual”, maybe use contractions and a friendly tone. If “formal”, be more structured and avoid slang.
      - Technical level: if user is novice, explain terms; if expert, use technical terms freely.
      - Any specific instructions user gave about style in prior conversation (like "Explain like I'm five" or "Keep it brief").
    - If no explicit preferences, use a default persona (maybe courteous and concise by default).
    - Check conversation context:
      - Has the AI used a certain tone so far? (Consistency is good; e.g., if it has been formal, generally stick to that unless user signals otherwise).
      - Are we delivering good/bad news or something requiring empathy? Adjust tone accordingly (this could be advanced; at least avoid insensitive phrasing).
 2. **Organize Content**:
    - Look at the raw content (Inference_Result):
      - If it's straightforward (like a single fact or a short answer), we can often just wrap it in a sentence or two with proper context: e.g., "Sure, ..." or "The answer is ...".
      - If it’s a list of points or multi-part answer, decide if listing them or paragraph form is better.
      - If there's supporting analysis that user might find interesting (and it's allowed to share), decide whether to include a brief mention. Some users might appreciate a one-sentence rationale: "I found this in the database from 2020..." (But ensure not to clutter if not asked).
      - Ensure the answer addresses the question fully:
        * If the inference result didn't explicitly mention part of question, consider adding a phrase to connect. (For example, user asks two things, M08 result has two numbers but not labeled; M14 might weave them: "X is ..., and Y is ...").
      - If any important caveats or uncertainty exist (especially if reasoning was unsure), express it in a polite way: "It appears that ..., though sources differ slightly."
    - Maintain coherence with context:
      - Avoid repeating the entire question in answer unless needed, but sometimes restating in brief shows you've got it: e.g., Q: "What's the weather?" A: "The weather in London today is sunny...".
      - If user used a certain term, use it too unless there's a reason to change (alignment).
 3. **Draft the Response**:
    - Create sentences or paragraphs:
      - Start possibly acknowledging question or as a direct answer depending on style. (E.g., "Your question was about X. Here's what I found:" vs just answering directly. This depends on how conversational to be.)
      - Provide the core answer early (don't bury the lede, user wants the info).
      - If needed, follow up with additional info or clarification.
      - Keep it as concise as possible while being complete (if user didn't ask for brevity, a little extra context is usually fine, but avoid going on tangents).
      - Use first-person or not depending on context: Many AI assistants say "I" to refer to themselves. If this is allowed and fits persona, fine. If wanting a more factual tone, could avoid "I". 
      - Possibly include a polite closing if appropriate (e.g., "Hope this helps!" or ask if they need more, but some flows avoid that every time).
    - Make sure grammar and spelling are correct. (We assume the AI's language model generation capabilities handle this implicitly, but logically it's a step.)
 4. **Incorporate Safety Considerations Preemptively**:
    - As you formulate, double-check that nothing in the content would trigger M11:
      - Avoid phrases that could be misinterpreted as offensive or too risky.
      - If the raw content included something borderline, maybe rephrase more neutrally.
      - E.g., if summarizing user’s possibly sensitive question, maybe phrase carefully or not mention certain triggering terms explicitly if not needed.
    - But do not remove needed info just out of fear, since M11 will catch actual violations. Just be mindful.
 5. **Finalize Outgoing Message**:
    - Output the composed message as **Outgoing_Message**.
    - This goes to M11 for final filtering. If M11 modifies it, okay, but aim that modifications will be minimal if M14 did a good job.
    - The orchestrator then sends Outgoing_Message to the user.
    - We do not usually loop after output, except if user responds again (new cycle).
    - If the content was entirely unsolvable or disallowed, and the Decision engine decided to refuse, M14 should formulate a polite refusal message (like "I'm sorry, I cannot assist with that request."). Possibly using a template or guidance from M11. M09 or M11 might also provide a refusal string; if not, M14 can have built-in standard lines for such cases when Inference_Result signals inability. Possibly triggered via a flag in the content or context (like result says "##REFUSE##" symbolically).
    - Provide that as Outgoing_Message in those cases as well.

RECURSION_CHECKS:
 - M14 should not call back to reasoning or other heavy modules. It's the end of the line for producing the text.
 - It might query user profile (M15) or context (M03) for info like name to personalize ("As we discussed earlier, [Name], ..."). That's fine and should be finite.
 - Avoid any dynamic content generation that isn't based on known info; it's assembling not deciding.
 - If uncertain about phrasing something sensitive, it's better to either omit or ask Safety (M11) for a check, but M11 will check anyway after. So no need for M14 to loop to M11 manually.
 
CHANGE_INSTRUCTIONS:
 - **Tone adjustments**: If feedback or design changes the persona (for instance, company wants the AI to always use a friendly emoji in casual chats or to avoid certain phrases), update the templating here.
   - Might maintain a style guide list like "never say 'as an AI, I ...'" or "always say 'please' when asking user something".
   - Implement those as rules in formatting.
 - **Multi-language support**: If user language can vary, incorporate a step to ensure output is in the correct language. Possibly M15 or context can indicate the language. If needed, translate the answer content from the internal language to user's language. If a translation model is available, call it; otherwise if the inference result was already in that language, just ensure phrasing is correct.
 - **Formatting**: If output platform supports markdown or HTML and user might benefit (like in code answers or list formatting), M14 can add those.
   - E.g., if answer contains code, maybe wrap in triple backticks for markdown.
   - If giving a list of steps, use bullet points.
   - These choices can be based on user preference or content detection (like if answer contains newline-separated items, consider formatting).
 - **Conciseness vs detail**: If often outputs are too long or too short, adjust logic.
   - Possibly measure length and enforce a limit if needed (like "if output > 5 sentences and user didn't ask for elaboration, maybe cut or ask if they want more").
   - Or if outputs are too terse and users ask follow-ups for more info, consider automatically adding a bit more explanation by default.
   - That might require learning from feedback; M13 could toggle a setting that M14 uses.
 - **Acknowledging mistakes**: If reflection found the answer might be incomplete but given anyway, maybe M14 can include a hedge or offer to find more info. But that might confuse if not asked. Usually better not unless user specifically asked for completeness check.
 - After changes, update **Version** and **Checksum**. If dependencies or usage of user profile changes, reflect that. 

---
Next_Suggest: (None – final step before output to user)
Alternate_Next: (None)
Resource_Usage: Moderate (language generation can be a bit heavy but not more than reasoning; mostly string assembly)
---