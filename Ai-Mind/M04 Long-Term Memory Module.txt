Module M04: Long-Term Memory Module

---
Module: M04_Long_Term_Memory
Version: 1.0
Purpose: Persist important information and knowledge over time and retrieve it on request
Triggers: [ "Archive_Request", "Knowledge_Query" ]
Inputs: [ "Item_to_Remember", "Memory_Search_Query" ]
Outputs: [ "Stored_Confirmation", "Knowledge_Results" ]
Dependencies: [ ]
Safety_Level: Moderate
Checksum: 9d04ca3fc0b6f7f4bb4a5ba80887457a
---

PURPOSE:
 The Long-Term Memory module functions as the AI’s durable knowledge base. It retains information that should persist beyond the immediate context – facts learned, user preferences (if explicitly stored here rather than in a separate profile module), historical conversation summaries, domain knowledge, etc. Over time, as the AI encounters new information or outcomes worth remembering, those are stored here so they can influence future decisions even after the short-term memory has cleared. This is analogous to a human’s long-term memory where important details, once learned, can be recalled much later. Additionally, this module handles queries for any information that isn’t readily available in short-term memory or needs a comprehensive search (like “what do we know about X?”).

INPUTS:
 - **Item_to_Remember (Archive_Request):** Data sent to be stored long-term. This could be triggered by M03 when short-term memory overflows, by M12/M13 when they conclude something should be memorized (e.g., a lesson learned or a user fact), or by any module that generates knowledge that should persist. Items might include: significant user facts (birthdays, names), conclusions from analysis (e.g., “User prefers concise answers”), or results of lengthy computations that we might reuse.
 - **Memory_Search_Query (Knowledge_Query):** A request to retrieve information from long-term memory. This could be a keyword search (“find info on topic Y”), a specific recall (“what was the outcome of task Z last week?”), or a general request for related knowledge (like a background knowledge fetch on something the user mentioned).

OUTPUTS:
 - **Stored_Confirmation:** After archiving, the module can output a confirmation (perhaps just a success flag or echo of stored item). Often this might not be needed explicitly unless debugging or the requesting module expects acknowledgment.
 - **Knowledge_Results:** The result of a memory query. Could be a set of data or notes retrieved that match the query. For example, if asked about “topic Y”, it might return a paragraph or list of relevant facts the system knows about Y. If multiple items match, it may return several or the most relevant few. If nothing relevant is found, it should indicate that (or return an empty set).
 - These outputs are then used by whichever module asked (often the Reasoning module M08 or Planner M07 will query knowledge to inform their processing).

DETAILED_DECISION_LOGIC:
 1. **Archive New Item** (on Archive_Request trigger):
    - Receive `Item_to_Remember` with content that should be stored. This could be text, a structured record, etc.
    - Optionally categorize or index the item: e.g., tag it with keywords, source (came from user vs came from system), date, etc. This helps later retrieval. If the item is textual, extracting keywords or summary might be useful.
    - Save the item into the long-term store. This store could be a simple list or appended text file (conceptually), or something more sophisticated like a key-value store or vector index. Initially, think of it as appending to a growing log or database of knowledge.
    - If the item replaces older info (e.g., user updated a preference), you might mark the old info as outdated or remove it. This requires identifying unique keys, which might not be trivial unless structured (for example, if storing facts as “key: value”). Our default is append-only unless explicitly pruned.
    - Output a `Stored_Confirmation` (could be a simple “OK” or the new total count of items, or echo).
    - Ensure the `Safety_Level` moderate is respected: i.e., if the item contains sensitive data, it’s being stored – that’s fine as long as retrieval and usage of it is controlled. The Safety module (M11) would later intercept if trying to output something sensitive.
 2. **Handle Knowledge Query** (on Memory_Search_Query trigger):
    - Parse the query. It might be:
      - A direct key lookup (e.g., “user_name” or “favorite_color”) if some data is stored in key-value format. 
      - A keyword or phrase search (e.g., “quantum physics”).
      - A more complex query sentence (“What did the AI do last time I asked about X?”).
    - Search the stored items:
      - If using simple text search: go through stored entries, find those that contain the query words or something semantically similar. You might do a case-insensitive substring match initially.
      - If items are categorized, filter by category first if applicable.
      - If the store is very large, in a real system one might use an inverted index or embedding similarity. In our context, assume manageable size where linear search is fine.
    - Rank matches by relevance (e.g., most recent relevant info might be more useful, or count of query term occurrences).
    - Compile results:
      - If one clear relevant item is found, output it as the result.
      - If multiple, you could either output all (perhaps in a list, capped at a certain number) or summarize them.
      - If none found, output `Knowledge_Results` indicating no match (or maybe an empty list or null).
    - The output format might be a text snippet or a data structure with references. For now, likely a text or a set of bullet points containing the found knowledge.
 3. **Maintenance** (background or as needed):
    - Over time, if the knowledge base grows large, implement a maintenance routine. This could be triggered manually or on a schedule (not real-time in conversation but as a separate maintenance mode).
    - Maintenance could include: removing duplicate entries, merging similar entries, summarizing older entries to free space, or re-indexing.
    - Also, if some info becomes invalid or outdated (like an old user preference replaced by a new one), you might mark it. This likely requires more structure (like unique keys), which we might implement later if needed.
 4. **Interface with Other Modules**:
    - M04 stands somewhat independent; no explicit dependencies listed because it can handle storage internally. But conceptually, it might share data with M15 (User Profile) or others. If user profile info is stored separately, M04 might not store those to avoid duplication. Clarify boundaries: possibly M15 handles known user preferences, while M04 handles everything else (general knowledge and experience).
    - Ensure queries meant for user profile (like “what’s the user’s name”) are either answered by M15 or by having M04 also contain that after an initial sync. This could be coordinated in the orchestrator or M06. For now, we treat M04 as the general catch-all memory.
    - If needed, incorporate a bridging logic: e.g., if a query is about user personal info, maybe forward it to M15. This isn’t implemented by default, but can be if needed.

RECURSION_CHECKS:
 - M04 should not call itself. It also should not unintentionally trigger M03 or others unless asked. There’s a potential subtle loop: if M03 can forward a query to M04 when not found in short-term (as mentioned in M03), ensure that M04 doesn’t then try to query short-term again. M04’s logic, as written, is self-contained: it answers from its own store only.
 - Avoid infinite archive loops: If some module inadvertently sends the same item repeatedly to archive, M04 doesn’t itself know it’s a duplicate unless explicitly checked. While not a recursion in code, that could lead to redundant data. If this becomes an issue, implement a check like “if new item text exactly matches an item added very recently, ignore it”.
 - Query responsiveness: If a poorly formed query is received (e.g., empty query), M04 should not loop. It should just return nothing or an error token without retrying endlessly.

CHANGE_INSTRUCTIONS:
 - **Storage format**: By default, think of M04 storing entries as plain text or simple records. If you want to structure this (for example, separate storage for different types of info), you could implement categories or a simple database. E.g., maintain dictionaries: one for “user_data”, one for “facts”, etc. Changing this means updating both archive (step 1) and query (step 2) logic to handle multiple stores or structured data.
 - **Indexing and search**: To improve retrieval, you might integrate an indexing mechanism. For example, maintain a dictionary mapping keywords to lists of entry IDs, or use an embedding-based approach for semantic search. These changes can make queries faster or more accurate. Document any added dependency (like if you use an external library for this).
 - **Entry summarization**: If memory grows, you might add a step when archiving: if the total entries exceed X, automatically summarize and merge older entries. This is complex (requires NLP summarization, possibly using the AI itself in a different mode). If implementing, consider doing it offline or sparingly to avoid heavy computation during conversation.
 - **Privacy and safety**: If certain items should never be retrieved unless specific conditions, mark them with flags. For instance, you might store raw conversation logs but not want to regurgitate them verbatim. You could mark such entries as “sensitive” and then during query, filter them out or only allow summarizing them, not quoting. Add such logic if needed (especially if storing user personal info or system prompts).
 - **Clearing memory**: If the user requests "forget X" or a data retention policy requires deleting certain info, implement a method to remove or mask entries. Currently, no explicit trigger for deletion is described, but you can conceive a special Archive_Request with an operation like "delete" and an identifier or content. That would require a search and remove operation in the archive.
 - After making changes, update **Version** and **Checksum**. If the interface (Inputs/Outputs) changes (like new formats or more structured responses), reflect that in those fields and ensure any module that interacts with M04 (M03, M07, M08, etc.) is aware of the new format.

---
Next_Suggest: (None direct)
Alternate_Next: (None direct)
Resource_Usage: Moderate (increases with amount of data; simple operations but potentially large memory usage over time)
---